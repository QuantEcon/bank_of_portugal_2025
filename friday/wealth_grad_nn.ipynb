{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30265622",
   "metadata": {},
   "source": [
    "# Policy Gradient-Based Deterministic Optimal Savings\n",
    "\n",
    "Author: [John Stachurski](https://johnstachurski.net)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we solve a deterministic infinite horizon optimal savings\n",
    "problem using policy gradient ascent with JAX. \n",
    "\n",
    "Each policy is represented as a fully connected feed forward neural network.\n",
    "\n",
    "Utility takes the CRRA form $u(c) = c^{1-\\gamma} / (1-\\gamma)$ and the discount factor is $\\beta$.\n",
    "\n",
    "Wealth evolves according to \n",
    "\n",
    "$$\n",
    "    w' = R (w - c) \n",
    "$$\n",
    "\n",
    "where $R > 0$ is the gross interest rate.  \n",
    "\n",
    "To ensure stability we check that $\\beta R^{1-\\gamma} < 1$.\n",
    "\n",
    "For this model, it is known that the optimal policy is $c = \\kappa w$, where\n",
    "\n",
    "$$\n",
    "    \\kappa := 1 - [\\beta R^{1-\\gamma}]^{1/\\gamma}\n",
    "$$\n",
    "\n",
    "We use this known exact solution to check our numerical methods.\n",
    "\n",
    "Initial wealth $w_0$ is fixed at 1.0, so the objective function is\n",
    "\n",
    "$$\n",
    "    \\max_{\\sigma \\in \\Sigma} v_\\sigma(w_0)\n",
    "    \\quad \\text{with} \\quad w_0 := 1.0\n",
    "$$\n",
    "\n",
    "Here \n",
    "\n",
    "* $\\Sigma$ is the set of all feasible policies and\n",
    "* $v_\\sigma(w)$ is the lifetime value of following stationary policy $\\sigma$, given initial wealth $w$.\n",
    "\n",
    "We begin with some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92aaea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, random\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740bce9f",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "We use a class called `Model` to store model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86760389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(NamedTuple):\n",
    "    \"\"\"\n",
    "    Stores parameters for the model.\n",
    "\n",
    "    \"\"\"\n",
    "    γ: float = 2.0\n",
    "    β: float = 0.95\n",
    "    R: float = 1.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c8517",
   "metadata": {},
   "source": [
    "We use a class called `LayerParams` to store parameters representing a single\n",
    "layer of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac3f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerParams(NamedTuple):\n",
    "    \"\"\"\n",
    "    Stores parameters for one layer of the neural network.\n",
    "\n",
    "    \"\"\"\n",
    "    W: jnp.ndarray     # weights\n",
    "    b: jnp.ndarray     # biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679cf0c",
   "metadata": {},
   "source": [
    "The next class stores some fixed values that form part of the network training\n",
    "configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27081872",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Configuration and parameters for training the neural network.\n",
    "\n",
    "    \"\"\"\n",
    "    seed = 42                    # Seed for network initialization\n",
    "    epochs = 500                 # No of training epochs\n",
    "    path_length = 1000           # Length of each consumption path\n",
    "    layer_sizes = 1, 8, 8, 1     # Network layer sizes\n",
    "    init_lr = 0.0015             # Learning rate schedule parameter\n",
    "    min_lr = 0.0001              # Learning rate schedule parameter\n",
    "    warmup_steps = 100           # Learning rate schedule parameter\n",
    "    decay_steps = 300            # Learning rate schedule parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce0cca",
   "metadata": {},
   "source": [
    "The following function initializes a single layer of the network using Le Cun\n",
    "initialization.\n",
    "\n",
    "(Le Cun initialization is thought to pair well with `selu` activation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95851d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_layer(in_dim, out_dim, key):\n",
    "    \"\"\"\n",
    "    Initialize weights and biases for a single layer of a the network.\n",
    "    Use LeCun initialization.\n",
    "\n",
    "    \"\"\"\n",
    "    s = jnp.sqrt(1.0 / in_dim)\n",
    "    W = jax.random.normal(key, (in_dim, out_dim)) * s\n",
    "    b = jnp.ones((out_dim,))\n",
    "    return LayerParams(W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6a4ad",
   "metadata": {},
   "source": [
    "The next function builds an entire network, as represented by its parameters, by\n",
    "initializing layers and stacking them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(key, layer_sizes):\n",
    "    \"\"\"\n",
    "    Build a network by initializing all of the parameters.\n",
    "    A network is a list of LayerParams instances, each \n",
    "    containing a weight-bias pair (W, b).\n",
    "\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    # For all layers but the output layer\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        # Build the layer \n",
    "        key, subkey = jax.random.split(key)\n",
    "        layer = initialize_layer(\n",
    "            layer_sizes[i],      # in dimension for layer\n",
    "            layer_sizes[i + 1],  # out dimension for layer\n",
    "            subkey \n",
    "        )\n",
    "        # And add it to the parameter list\n",
    "        params.append(layer)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df47833",
   "metadata": {},
   "source": [
    "Now we provide a function to do a forward pass through the network, given the\n",
    "parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(params, w):\n",
    "    \"\"\"\n",
    "    Evaluate neural network policy: maps a given wealth level w to a rate of\n",
    "    consumption c/w by running a forward pass through the network.\n",
    "\n",
    "    \"\"\"\n",
    "    σ = jax.nn.selu          # Activation function\n",
    "    x = jnp.array((w,))      # Make state a 1D array\n",
    "    # Forward pass through network, without the last step\n",
    "    for W, b in params[:-1]:\n",
    "        x = σ(x @ W + b)\n",
    "    # Complete with sigmoid activation for consumption rate\n",
    "    W, b = params[-1]\n",
    "    x = jax.nn.sigmoid(x @ W + b)\n",
    "    # Extract and return\n",
    "    consumption_rate = x[0]\n",
    "    return consumption_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8683021d",
   "metadata": {},
   "source": [
    "We use CRRA utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160848e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(c, γ):\n",
    "    \"\"\" Utility function. \"\"\"\n",
    "    c = jnp.maximum(c, 1e-10)\n",
    "    return c**(1 - γ) / (1 - γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a28ed5",
   "metadata": {},
   "source": [
    "The next function approximates lifetime value associated with a given policy, as\n",
    "represented by the parameters of a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438208a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=('path_length'))\n",
    "def compute_lifetime_value(params, model, path_length):\n",
    "    \"\"\"\n",
    "    Compute the lifetime value of a path generated from\n",
    "    the policy embedded in params and the initial condition w_0 = 1.\n",
    "\n",
    "    \"\"\"\n",
    "    γ, β, R = model.γ, model.β, model.R\n",
    "    initial_w = 1.0\n",
    "\n",
    "    def update(t, state):\n",
    "        # Unpack and compute consumption given current wealth\n",
    "        w, value, discount = state\n",
    "        consumption_rate = forward(params, w)\n",
    "        c = consumption_rate * w\n",
    "        # Update loop state and return it\n",
    "        w = R * (w - c)\n",
    "        value = value + discount * u(c, γ) \n",
    "        discount = discount * β\n",
    "        new_state = w, value, discount\n",
    "        return new_state\n",
    "    \n",
    "    initial_value, initial_discount = 0.0, 1.0\n",
    "    initial_state = initial_w, initial_value, initial_discount\n",
    "    final_w, final_value, discount = jax.lax.fori_loop(\n",
    "        0, path_length, update, initial_state\n",
    "    )\n",
    "    return final_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a989941c",
   "metadata": {},
   "source": [
    "Here's the loss function we will minimize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(params, model, path_length):\n",
    "    \"\"\"\n",
    "    Loss is the negation of the lifetime value of the policy \n",
    "    identified by `params`.\n",
    "\n",
    "    \"\"\"\n",
    "    return -compute_lifetime_value(params, model, path_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984281f",
   "metadata": {},
   "source": [
    "We create a standard Optax learning rate scheduler, which controls the time path\n",
    "of the learning parameter over the process of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f43aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lr_schedule():\n",
    "    warmup_fn = optax.linear_schedule(\n",
    "        init_value=0.0,\n",
    "        end_value=Config.init_lr,\n",
    "        transition_steps=Config.warmup_steps\n",
    "    )\n",
    "    \n",
    "    decay_fn = optax.exponential_decay(\n",
    "        init_value=Config.init_lr,\n",
    "        transition_steps=Config.decay_steps,\n",
    "        decay_rate=0.5,\n",
    "        end_value=Config.min_lr\n",
    "    )\n",
    "    \n",
    "    return optax.join_schedules(\n",
    "        schedules=[warmup_fn, decay_fn],\n",
    "        boundaries=[Config.warmup_steps]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c30f281",
   "metadata": {},
   "source": [
    "## Train and solve \n",
    "\n",
    "First we create an instance of the model and unpack names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "γ, β, R = model.γ, model.β, model.R\n",
    "seed, epochs = Config.seed, Config.epochs\n",
    "path_length = Config.path_length\n",
    "layer_sizes = Config.layer_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe0253f",
   "metadata": {},
   "source": [
    "We test stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert β * R**(1 - γ) < 1, \"Parameters fail stability test.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f83cf",
   "metadata": {},
   "source": [
    "We compute the optimal consumption rate and lifetime value from the analytical\n",
    "expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca71be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "κ = 1 - (β * R**(1 - γ))**(1/γ)\n",
    "print(f\"Optimal savings rate = {κ}.\\n\")\n",
    "v_max = κ**(-γ) * u(1.0, γ)\n",
    "print(f\"Theoretical maximum lifetime value = {v_max}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d94737d",
   "metadata": {},
   "source": [
    "Let's now create a learning rate schedule and set up the Optax minimizer, using\n",
    "[Adam](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = create_lr_schedule()\n",
    "optimizer = optax.chain(\n",
    "    optax.clip_by_global_norm(1.0),  # Gradient clipping for stability\n",
    "    optax.adam(learning_rate=lr_schedule)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f5a83f",
   "metadata": {},
   "source": [
    "We initialize the parameters in the neural network and the state of the\n",
    "optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572146b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(seed)\n",
    "params = initialize_network(key, layer_sizes)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e78814",
   "metadata": {},
   "source": [
    "Now let's train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd28d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_history = []\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Compute value and gradients at existing parameterization\n",
    "    loss, grads = jax.value_and_grad(loss_function)(params, model, path_length)\n",
    "    lifetime_value = - loss\n",
    "    value_history.append(lifetime_value)\n",
    "    \n",
    "    # Update parameters using optimizer\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}: Value = {lifetime_value:.4f}\")\n",
    "\n",
    "\n",
    "print(f\"\\nFinal value: {value_history[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0f2af",
   "metadata": {},
   "source": [
    "First we plot the evolution of lifetime value over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning progress\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(value_history, 'b-', linewidth=2)\n",
    "ax.set_xlabel('iteration')\n",
    "ax.set_ylabel('policy value')\n",
    "ax.set_title('learning progress')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6c11c",
   "metadata": {},
   "source": [
    "Next we compare the learned and optimal policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_grid = jnp.linspace(0.01, 1.0, 1000)\n",
    "policy_vmap = jax.vmap(lambda w: forward(params, w))\n",
    "consumption_rate = policy_vmap(w_grid)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(w_grid, consumption_rate, linestyle='--', lw=4, label='learned policy')\n",
    "ax.plot(w_grid, κ * jnp.ones(len(w_grid)), lw=2, label='optimal')\n",
    "ax.set_xlabel('wealth')\n",
    "ax.set_ylabel('consumption rate (c/w)')\n",
    "ax.set_title('Consumption rate')\n",
    "ax.set_ylim((0, 0.1))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ec422",
   "metadata": {},
   "source": [
    "Let's have a look at paths for consumption and wealth under the learned and\n",
    "optimal policies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e98387",
   "metadata": {},
   "source": [
    "The figures below show that the learned policies are close to optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_consumption_path(params, T=120):\n",
    "    \"\"\"\n",
    "    Compute consumption path using neural network policy identified by params.\n",
    "\n",
    "    \"\"\"\n",
    "    w_sim = [1.0]   # 1.0 is the initial wealth\n",
    "    c_sim = []\n",
    "    w_opt = [1.0]  \n",
    "    c_opt = []\n",
    "\n",
    "    w = 1.0\n",
    "    for t in range(T):\n",
    "\n",
    "        # Update policy path\n",
    "        c = forward(params, w) * w\n",
    "        c_sim.append(float(c))\n",
    "        w = R * (w - c)\n",
    "        w_sim.append(float(w))\n",
    "        \n",
    "        if w <= 1e-10:\n",
    "            break\n",
    "\n",
    "    w = 1.0\n",
    "    for t in range(T):\n",
    "\n",
    "        # Update optimal path\n",
    "        c = κ * w\n",
    "        c_opt.append(c)\n",
    "        w = R * (w - c)\n",
    "        w_opt.append(w)\n",
    "        \n",
    "        if w <= 1e-10:\n",
    "            break\n",
    "    \n",
    "    return w_sim, c_sim, w_opt, c_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate and plot path\n",
    "w_sim, c_sim, w_opt, c_opt = simulate_consumption_path(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6fcd2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.plot(w_sim, lw=4, linestyle='--', label='learned policy')\n",
    "ax1.plot(w_opt, lw=2, label='optimal')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Wealth')\n",
    "ax1.set_title('Wealth over time')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(c_sim, lw=4, linestyle='--', label='learned policy')\n",
    "ax2.plot(c_opt, lw=2, label='optimal')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Consumption')\n",
    "ax2.set_title('Consumption over time')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f603ad",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
