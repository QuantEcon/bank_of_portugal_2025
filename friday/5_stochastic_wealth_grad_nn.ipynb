{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a333890",
   "metadata": {},
   "source": [
    "# Policy Gradient-Based Deterministic Optimal Savings\n",
    "\n",
    "Author: [John Stachurski](https://johnstachurski.net)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we solve a deterministic infinite horizon optimal savings\n",
    "problem using policy gradient ascent with JAX. \n",
    "\n",
    "Each policy is represented as a fully connected feed forward neural network.\n",
    "\n",
    "Utility takes the CRRA form $u(c) = c^{1-\\gamma} / (1-\\gamma)$ and the discount factor is $\\beta$.\n",
    "\n",
    "Wealth evolves according to \n",
    "\n",
    "$$\n",
    "    w' = R (w - c) + Y'\n",
    "$$\n",
    "\n",
    "where $R > 0$ is the gross interest rate and $Y'$ is an IID lognormal draw.  \n",
    "\n",
    "To ensure stability we check that $\\beta R^{1-\\gamma} < 1$.\n",
    "\n",
    "Initial wealth $w_0$ is fixed at 1.0, so the objective function is\n",
    "\n",
    "$$\n",
    "    \\max_{\\sigma \\in \\Sigma} v_\\sigma(w_0)\n",
    "    \\quad \\text{with} \\quad w_0 := 1.0\n",
    "$$\n",
    "\n",
    "Here \n",
    "\n",
    "* $\\Sigma$ is the set of all feasible policies and\n",
    "* $v_\\sigma(w)$ is the lifetime value of following stationary policy $\\sigma$, given initial wealth $w$.\n",
    "\n",
    "We begin with some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9accc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, random\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb407366",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "We use a class called `Model` to store model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(NamedTuple):\n",
    "    \"\"\"\n",
    "    Stores parameters for the model.\n",
    "\n",
    "    \"\"\"\n",
    "    γ: float = 0.2    # Utility parameter\n",
    "    β: float = 0.96   # Discount factor\n",
    "    R: float = 1.01   # Gross interest rate\n",
    "    μ: float = 0.0    # income location parameter\n",
    "    ν: float = 0.4    # income volatility parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfbac16",
   "metadata": {},
   "source": [
    "We use a class called `LayerParams` to store parameters representing a single\n",
    "layer of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd745ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerParams(NamedTuple):\n",
    "    \"\"\"\n",
    "    Stores parameters for one layer of the neural network.\n",
    "\n",
    "    \"\"\"\n",
    "    W: jnp.ndarray     # weights\n",
    "    b: jnp.ndarray     # biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65405074",
   "metadata": {},
   "source": [
    "The next class stores some fixed values that form part of the network training\n",
    "configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Configuration and parameters for training the neural network.\n",
    "\n",
    "    \"\"\"\n",
    "    seed = 42                       # Seed for network initialization\n",
    "    epochs = 1500                   # No of training epochs\n",
    "    layer_sizes = 1, 32, 32, 32, 1  # Network layer sizes\n",
    "    init_lr = 0.01                  # Learning rate schedule parameter\n",
    "    min_lr = 0.001                  # Learning rate schedule parameter\n",
    "    warmup_steps = 100              # Learning rate schedule parameter\n",
    "    decay_steps = 300               # Learning rate schedule parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d92b768",
   "metadata": {},
   "source": [
    "The following function initializes a single layer of the network using Le Cun\n",
    "initialization.\n",
    "\n",
    "(Le Cun initialization is thought to pair well with `selu` activation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b147448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_layer(in_dim, out_dim, key):\n",
    "    \"\"\"\n",
    "    Initialize weights and biases for a single layer of a the network.\n",
    "\n",
    "    \"\"\"\n",
    "    s = jnp.sqrt(1.0 / in_dim)\n",
    "    W = jax.random.normal(key, (in_dim, out_dim)) * s\n",
    "    b = jnp.ones((out_dim,))\n",
    "    return LayerParams(W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b3751",
   "metadata": {},
   "source": [
    "The next function builds an entire network, as represented by its parameters, by\n",
    "initializing layers and stacking them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(key, layer_sizes):\n",
    "    \"\"\"\n",
    "    Build a network by initializing all of the parameters.\n",
    "    A network is a list of LayerParams instances, each \n",
    "    containing a weight-bias pair (W, b).\n",
    "\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    # For all layers but the output layer\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        # Build the layer \n",
    "        key, subkey = jax.random.split(key)\n",
    "        layer = initialize_layer(\n",
    "            layer_sizes[i],      # in dimension for layer\n",
    "            layer_sizes[i + 1],  # out dimension for layer\n",
    "            subkey \n",
    "        )\n",
    "        # And add it to the parameter list\n",
    "        params.append(layer)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bcd32a",
   "metadata": {},
   "source": [
    "Now we provide a function to do a forward pass through the network, given the\n",
    "parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(params, w):\n",
    "    \"\"\"\n",
    "    Evaluate neural network policy: maps a given wealth level w to a rate of\n",
    "    consumption c/w by running a forward pass through the network.\n",
    "\n",
    "    Assumes w is an array.\n",
    "\n",
    "    \"\"\"\n",
    "    σ = jax.nn.selu          # Activation function\n",
    "    x = w.reshape(-1, 1)     # Shape: (batch_size, 1)\n",
    "    # Forward pass through network, without the last step\n",
    "    for W, b in params[:-1]:\n",
    "        x = σ(x @ W + b)\n",
    "    # Complete with sigmoid activation for consumption rate\n",
    "    W, b = params[-1]\n",
    "    x = jax.nn.sigmoid(x @ W + b)\n",
    "    # Return squeezed output (flatten array)\n",
    "    return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d8f23",
   "metadata": {},
   "source": [
    "We use CRRA utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b4c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(c, γ):\n",
    "    \"\"\" Utility function. \"\"\"\n",
    "    c = jnp.maximum(c, 1e-10)\n",
    "    return c**(1 - γ) / (1 - γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f25363",
   "metadata": {},
   "source": [
    "The next function approximates lifetime value associated with a given policy, as\n",
    "represented by the parameters of a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b835219",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=('cross_section_size', 'path_length'))\n",
    "def compute_lifetime_value(\n",
    "        key,\n",
    "        params, \n",
    "        model, \n",
    "        cross_section_size, \n",
    "        path_length\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Compute the lifetime value of a path generated from\n",
    "\n",
    "    1. the policy associated with params \n",
    "    2. the initial condition w_0 = 1.\n",
    "\n",
    "    \"\"\"\n",
    "    γ, β, R, μ, σ = model\n",
    "    initial_w = jnp.full(cross_section_size, 1.0)  # Start everyone at 1.0\n",
    "\n",
    "    def update(t, loop_state):\n",
    "        # Unpack and compute consumption given current wealth\n",
    "        key, w, value, discount = loop_state\n",
    "        consumption_rate = forward(params, w)\n",
    "        c = consumption_rate * w\n",
    "        # Update loop state and return it\n",
    "        key, subkey = jax.random.split(key)\n",
    "        Z = jax.random.normal(subkey, (cross_section_size,))\n",
    "        Y = jnp.exp(μ + σ * Z)\n",
    "        w = R * (w - c) + Y\n",
    "        value = value + discount * u(c, γ) \n",
    "        discount = discount * β\n",
    "        new_loop_state = key, w, value, discount\n",
    "        return new_loop_state\n",
    "    \n",
    "    initial_value = jnp.zeros(cross_section_size)\n",
    "    initial_discount = 1.0\n",
    "    initial_state = key, initial_w, initial_value, initial_discount\n",
    "    final_key, final_w, final_value, discount = jax.lax.fori_loop(\n",
    "        0, path_length, update, initial_state\n",
    "    )\n",
    "    return jnp.mean(final_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8036fc9e",
   "metadata": {},
   "source": [
    "Here's the loss function we will minimize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236fcd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(\n",
    "        params,\n",
    "        model,\n",
    "        cross_section_size=5_000,\n",
    "        path_length=500,\n",
    "        seed=42):\n",
    "    \"\"\"\n",
    "    Loss is the negation of the lifetime value of the policy\n",
    "    identified by `params`.\n",
    "\n",
    "    \"\"\"\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    loss = - compute_lifetime_value(\n",
    "        key, params, model, cross_section_size, path_length\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b3dd6",
   "metadata": {},
   "source": [
    "We create a standard Optax learning rate scheduler, which controls the time path\n",
    "of the learning parameter over the process of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ba6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lr_schedule():\n",
    "    warmup_fn = optax.linear_schedule(\n",
    "        init_value=0.0,\n",
    "        end_value=Config.init_lr,\n",
    "        transition_steps=Config.warmup_steps\n",
    "    )\n",
    "    \n",
    "    decay_fn = optax.exponential_decay(\n",
    "        init_value=Config.init_lr,\n",
    "        transition_steps=Config.decay_steps,\n",
    "        decay_rate=0.5,\n",
    "        end_value=Config.min_lr\n",
    "    )\n",
    "    \n",
    "    return optax.join_schedules(\n",
    "        schedules=[warmup_fn, decay_fn],\n",
    "        boundaries=[Config.warmup_steps]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f4009b",
   "metadata": {},
   "source": [
    "## Train and solve \n",
    "\n",
    "First we create an instance of the model and unpack names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4576b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "γ, β, R, μ, σ = model\n",
    "seed, epochs = Config.seed, Config.epochs\n",
    "layer_sizes = Config.layer_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d75ed",
   "metadata": {},
   "source": [
    "We test stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c057581",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert β * R**(1 - γ) < 1, \"Parameters fail stability test.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa8f9c",
   "metadata": {},
   "source": [
    "Let's now create a learning rate schedule and set up the Optax minimizer, using\n",
    "[Adam](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e535f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = create_lr_schedule()\n",
    "optimizer = optax.chain(\n",
    "    optax.clip_by_global_norm(1.0),  # Gradient clipping for stability\n",
    "    optax.adam(learning_rate=lr_schedule)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0f3de",
   "metadata": {},
   "source": [
    "We initialize the parameters in the neural network and the state of the\n",
    "optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(seed)\n",
    "params = initialize_network(key, layer_sizes)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf9ae3",
   "metadata": {},
   "source": [
    "Now let's train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_history = []\n",
    "grad_norm_history = []\n",
    "key = random.PRNGKey(seed)\n",
    "for i in range(epochs):\n",
    "\n",
    "    # Generate new random seed for this iteration\n",
    "    key, subkey = random.split(key)\n",
    "    iteration_seed = int(random.randint(subkey, (), 0, 2**31 - 1))\n",
    "\n",
    "    # Compute value and gradients at existing parameterization\n",
    "    loss, grads = jax.value_and_grad(loss_function)(params, model, seed=iteration_seed)\n",
    "    lifetime_value = - loss\n",
    "    value_history.append(lifetime_value)\n",
    "\n",
    "    # Compute gradient norm\n",
    "    grad_norm = jnp.sqrt(sum(jnp.sum(g.W**2) + jnp.sum(g.b**2) for g in grads))\n",
    "    grad_norm_history.append(grad_norm)\n",
    "\n",
    "    # Update parameters using optimizer\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}: Value = {lifetime_value:.4f}, Grad Norm = {grad_norm:.6f}\")\n",
    "\n",
    "\n",
    "print(f\"\\nFinal value: {value_history[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ae71e",
   "metadata": {},
   "source": [
    "First we plot the evolution of lifetime value over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d603f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning progress\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(value_history, 'b-', linewidth=2)\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('policy value')\n",
    "ax1.set_title('learning progress')\n",
    "\n",
    "ax2.plot(grad_norm_history, 'r-', linewidth=2)\n",
    "ax2.set_xlabel('iteration')\n",
    "ax2.set_ylabel('gradient norm')\n",
    "ax2.set_title('gradient norm over training')\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1daa0",
   "metadata": {},
   "source": [
    "Next we plot the optimal consumption and savings policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_grid = jnp.linspace(0.01, 10.0, 1000)\n",
    "consumption_rate = forward(params, w_grid)\n",
    "consumption = consumption_rate * w_grid\n",
    "savings = w_grid - consumption\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(w_grid, w_grid, linestyle='--', color='k', label='45 degrees')\n",
    "ax.plot(w_grid, consumption, label='consumption policy')\n",
    "ax.plot(w_grid, savings, label='savings policy')\n",
    "ax.set_xlabel('wealth')\n",
    "ax.set_ylabel('consumption')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97a013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
