{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86154c66",
   "metadata": {},
   "source": [
    "# Policy Gradient-Based Deterministic Optimal Savings\n",
    "\n",
    "Author: [John Stachurski](https://johnstachurski.net)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we solve a deterministic infinite horizon optimal savings\n",
    "problem using policy gradient ascent with JAX. \n",
    "\n",
    "Each policy is represented as a fully connected feed forward neural network.\n",
    "\n",
    "Utility takes the CRRA form $u(c) = c^{1-\\gamma} / (1-\\gamma)$ and the discount factor is $\\beta$.\n",
    "\n",
    "Wealth evolves according to \n",
    "\n",
    "$$\n",
    "    w' = R (w - c) + Y'\n",
    "$$\n",
    "\n",
    "where $R > 0$ is the gross interest rate and $Y'$ is an IID lognormal draw.  \n",
    "\n",
    "To ensure stability we check that $\\beta R^{1-\\gamma} < 1$.\n",
    "\n",
    "Initial wealth $w_0$ is fixed at 1.0, so the objective function is\n",
    "\n",
    "$$\n",
    "    \\max_{\\sigma \\in \\Sigma} v_\\sigma(w_0)\n",
    "    \\quad \\text{with} \\quad w_0 := 1.0\n",
    "$$\n",
    "\n",
    "Here \n",
    "\n",
    "* $\\Sigma$ is the set of all feasible policies and\n",
    "* $v_\\sigma(w)$ is the lifetime value of following stationary policy $\\sigma$, given initial wealth $w$.\n",
    "\n",
    "We begin with some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98a718",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, random\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9a1b0",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "We use a class called `Model` to store model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f00889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(NamedTuple):\n",
    "    \"\"\"\n",
    "    Stores parameters for the model.\n",
    "\n",
    "    \"\"\"\n",
    "    γ: float = 1.5    # Utility parameter\n",
    "    β: float = 0.96   # Discount factor\n",
    "    R: float = 1.01   # Gross interest rate\n",
    "    μ: float = -1.0   # income location parameter\n",
    "    ν: float = 0.2    # income volatility parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252181d",
   "metadata": {},
   "source": [
    "We use a class called `LayerParams` to store parameters representing a single\n",
    "layer of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerParams(NamedTuple):\n",
    "    \"\"\"\n",
    "    Stores parameters for one layer of the neural network.\n",
    "\n",
    "    \"\"\"\n",
    "    W: jnp.ndarray     # weights\n",
    "    b: jnp.ndarray     # biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca131f85",
   "metadata": {},
   "source": [
    "The next class stores some fixed values that form part of the network training\n",
    "configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6293745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Configuration and parameters for training the neural network.\n",
    "\n",
    "    \"\"\"\n",
    "    seed = 42                    # Seed for network initialization\n",
    "    epochs = 250                 # No of training epochs\n",
    "    layer_sizes = 1, 12, 12, 1   # Network layer sizes\n",
    "    init_lr = 0.0015             # Learning rate schedule parameter\n",
    "    min_lr = 0.0001              # Learning rate schedule parameter\n",
    "    warmup_steps = 100           # Learning rate schedule parameter\n",
    "    decay_steps = 300            # Learning rate schedule parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fee552",
   "metadata": {},
   "source": [
    "The following function initializes a single layer of the network using Le Cun\n",
    "initialization.\n",
    "\n",
    "(Le Cun initialization is thought to pair well with `selu` activation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd294a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_layer(in_dim, out_dim, key):\n",
    "    \"\"\"\n",
    "    Initialize weights and biases for a single layer of a the network.\n",
    "\n",
    "    \"\"\"\n",
    "    s = jnp.sqrt(1.0 / in_dim)\n",
    "    W = jax.random.normal(key, (in_dim, out_dim)) * s\n",
    "    b = jnp.ones((out_dim,))\n",
    "    return LayerParams(W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c49a1",
   "metadata": {},
   "source": [
    "The next function builds an entire network, as represented by its parameters, by\n",
    "initializing layers and stacking them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(key, layer_sizes):\n",
    "    \"\"\"\n",
    "    Build a network by initializing all of the parameters.\n",
    "    A network is a list of LayerParams instances, each \n",
    "    containing a weight-bias pair (W, b).\n",
    "\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    # For all layers but the output layer\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        # Build the layer \n",
    "        key, subkey = jax.random.split(key)\n",
    "        layer = initialize_layer(\n",
    "            layer_sizes[i],      # in dimension for layer\n",
    "            layer_sizes[i + 1],  # out dimension for layer\n",
    "            subkey \n",
    "        )\n",
    "        # And add it to the parameter list\n",
    "        params.append(layer)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ae667",
   "metadata": {},
   "source": [
    "Now we provide a function to do a forward pass through the network, given the\n",
    "parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(params, w):\n",
    "    \"\"\"\n",
    "    Evaluate neural network policy: maps a given wealth level w to a rate of\n",
    "    consumption c/w by running a forward pass through the network.\n",
    "\n",
    "    Assumes w is an array.\n",
    "\n",
    "    \"\"\"\n",
    "    σ = jax.nn.selu          # Activation function\n",
    "    x = w.reshape(-1, 1)     # Shape: (batch_size, 1)\n",
    "    # Forward pass through network, without the last step\n",
    "    for W, b in params[:-1]:\n",
    "        x = σ(x @ W + b)\n",
    "    # Complete with sigmoid activation for consumption rate\n",
    "    W, b = params[-1]\n",
    "    x = jax.nn.sigmoid(x @ W + b)\n",
    "    # Return squeezed output (flatten array)\n",
    "    return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4cede",
   "metadata": {},
   "source": [
    "We use CRRA utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(c, γ):\n",
    "    \"\"\" Utility function. \"\"\"\n",
    "    c = jnp.maximum(c, 1e-10)\n",
    "    return c**(1 - γ) / (1 - γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3602a4b8",
   "metadata": {},
   "source": [
    "The next function approximates lifetime value associated with a given policy, as\n",
    "represented by the parameters of a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=('cross_section_size', 'path_length'))\n",
    "def compute_lifetime_value(\n",
    "        key,\n",
    "        params, \n",
    "        model, \n",
    "        cross_section_size, \n",
    "        path_length\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Compute the lifetime value of a path generated from\n",
    "\n",
    "    1. the policy associated with params \n",
    "    2. the initial condition w_0 = 1.\n",
    "\n",
    "    \"\"\"\n",
    "    γ, β, R, μ, σ = model\n",
    "    initial_w = jnp.full(cross_section_size, 1.0)  # Start everyone at 1.0\n",
    "\n",
    "    def update(t, loop_state):\n",
    "        # Unpack and compute consumption given current wealth\n",
    "        key, w, value, discount = loop_state\n",
    "        consumption_rate = forward(params, w)\n",
    "        c = consumption_rate * w\n",
    "        # Update loop state and return it\n",
    "        key, subkey = jax.random.split(key)\n",
    "        Z = jax.random.normal(subkey, (cross_section_size,))\n",
    "        Y = jnp.exp(μ + σ * Z)\n",
    "        w = R * (w - c) + Y\n",
    "        value = value + discount * u(c, γ) \n",
    "        discount = discount * β\n",
    "        new_loop_state = key, w, value, discount\n",
    "        return new_loop_state\n",
    "    \n",
    "    initial_value = jnp.zeros(cross_section_size)\n",
    "    initial_discount = 1.0\n",
    "    initial_state = key, initial_w, initial_value, initial_discount\n",
    "    final_key, final_w, final_value, discount = jax.lax.fori_loop(\n",
    "        0, path_length, update, initial_state\n",
    "    )\n",
    "    return jnp.mean(final_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb589870",
   "metadata": {},
   "source": [
    "Here's the loss function we will minimize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f33677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(\n",
    "        params, \n",
    "        model, \n",
    "        cross_section_size=1_000,\n",
    "        path_length=1_000, \n",
    "        seed=42):\n",
    "    \"\"\"\n",
    "    Loss is the negation of the lifetime value of the policy \n",
    "    identified by `params`.\n",
    "\n",
    "    \"\"\"\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    loss = - compute_lifetime_value(\n",
    "        key, params, model, cross_section_size, path_length\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10023b26",
   "metadata": {},
   "source": [
    "We create a standard Optax learning rate scheduler, which controls the time path\n",
    "of the learning parameter over the process of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbcafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lr_schedule():\n",
    "    warmup_fn = optax.linear_schedule(\n",
    "        init_value=0.0,\n",
    "        end_value=Config.init_lr,\n",
    "        transition_steps=Config.warmup_steps\n",
    "    )\n",
    "    \n",
    "    decay_fn = optax.exponential_decay(\n",
    "        init_value=Config.init_lr,\n",
    "        transition_steps=Config.decay_steps,\n",
    "        decay_rate=0.5,\n",
    "        end_value=Config.min_lr\n",
    "    )\n",
    "    \n",
    "    return optax.join_schedules(\n",
    "        schedules=[warmup_fn, decay_fn],\n",
    "        boundaries=[Config.warmup_steps]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b097051",
   "metadata": {},
   "source": [
    "## Train and solve \n",
    "\n",
    "First we create an instance of the model and unpack names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "γ, β, R, μ, σ = model\n",
    "seed, epochs = Config.seed, Config.epochs\n",
    "layer_sizes = Config.layer_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce6fe8a",
   "metadata": {},
   "source": [
    "We test stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa19efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert β * R**(1 - γ) < 1, \"Parameters fail stability test.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd8b36",
   "metadata": {},
   "source": [
    "Let's now create a learning rate schedule and set up the Optax minimizer, using\n",
    "[Adam](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = create_lr_schedule()\n",
    "optimizer = optax.chain(\n",
    "    optax.clip_by_global_norm(1.0),  # Gradient clipping for stability\n",
    "    optax.adam(learning_rate=lr_schedule)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57021c3d",
   "metadata": {},
   "source": [
    "We initialize the parameters in the neural network and the state of the\n",
    "optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd08190",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(seed)\n",
    "params = initialize_network(key, layer_sizes)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7389729",
   "metadata": {},
   "source": [
    "Now let's train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f703fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_history = []\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Compute value and gradients at existing parameterization\n",
    "    loss, grads = jax.value_and_grad(loss_function)(params, model)\n",
    "    lifetime_value = - loss\n",
    "    value_history.append(lifetime_value)\n",
    "    \n",
    "    # Update parameters using optimizer\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}: Value = {lifetime_value:.4f}\")\n",
    "\n",
    "\n",
    "print(f\"\\nFinal value: {value_history[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ba952",
   "metadata": {},
   "source": [
    "First we plot the evolution of lifetime value over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d750ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning progress\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(value_history, 'b-', linewidth=2)\n",
    "ax.set_xlabel('iteration')\n",
    "ax.set_ylabel('policy value')\n",
    "ax.set_title('learning progress')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb4e02",
   "metadata": {},
   "source": [
    "Next we plot the optimal consumption and savings policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_grid = jnp.linspace(0.01, 1.0, 1000)\n",
    "consumption_rate = forward(params, w_grid)\n",
    "consumption = consumption_rate * w_grid\n",
    "savings = w_grid - consumption\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(w_grid, w_grid, linestyle='--', color='k', label='45 degrees')\n",
    "ax.plot(w_grid, consumption, label='consumption policy')\n",
    "ax.plot(w_grid, savings, label='savings policy')\n",
    "ax.set_xlabel('wealth')\n",
    "ax.set_ylabel('consumption')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
