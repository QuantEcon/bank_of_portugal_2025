











!pip install --upgrade keras





import os
os.environ['KERAS_BACKEND'] = 'jax'





import keras


from keras import Sequential
from keras.layers import Dense





import numpy as np
import matplotlib.pyplot as plt





def generate_data(x_min=0,           # Minimum x value
                  x_max=5,           # Max x value
                  data_size=400,     # Default size for dataset
                  seed=1234):
    np.random.seed(seed)
    x = np.linspace(x_min, x_max, num=data_size)
    # y = f(x) + ϵ with f as below
    ϵ = 0.2 * np.random.randn(data_size)
    y = x**0.5 + np.sin(x) + ϵ
    # Transform to column vectors (Keras expects two dimensions, not flat arrays)
    x, y = [np.reshape(z, (data_size, 1)) for z in (x, y)]
    return x, y





x, y = generate_data()





fig, ax = plt.subplots()
ax.scatter(x, y)
ax.set_xlabel('x')
ax.set_ylabel('y')
plt.show()





x_validate, y_validate = generate_data()








def build_regression_model():
    # Generate an instance of Sequential, to store layers and training attributes
    model = Sequential()
    # Add a single layer with scalar output
    model.add(Dense(units=1))  
    # Configure the model for training
    model.compile(optimizer=keras.optimizers.SGD(), 
                  loss='mean_squared_error')
    return model








def build_nn_model(output_dim=10, num_layers=3, activation_function='tanh'):
    # Create a Keras Model instance using Sequential()
    model = Sequential()
    # Add layers to the network sequentially, from inputs towards outputs
    for i in range(num_layers):
        model.add(Dense(units=output_dim, activation=activation_function))
    # Add a final layer that maps to a scalar value, for regression.
    model.add(Dense(units=1))
    # Embed training configurations
    model.compile(optimizer=keras.optimizers.SGD(), 
                  loss='mean_squared_error')
    return model





def plot_loss_history(training_history, ax):
    """
    Plot the MSE of the training data as a function of the epochs.  
    Each epoch corresponds to one pass through the data set and update of
    the parameters.

    This function acts on the training history returned by a call to the
    `fit` method of a given model.
    """
    epochs = training_history.epoch
    training_losses = training_history.history['loss']
    validation_losses = training_history.history['val_loss']
    ax.plot(epochs, 
            training_losses, 
            label='training loss')
    # Plot MSE of validation data against epoch
    ax.plot(epochs, 
            validation_losses,
            label='validation loss')
    # Add labels
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Loss (Mean squared error)')
    ax.legend()








regression_model = build_regression_model()





training_history = regression_model.fit(
    x, y, 
    batch_size=x.shape[0], 
    verbose=0,
    epochs=2000, 
    validation_data=(x_validate, y_validate)
)





fig, ax = plt.subplots()
plot_loss_history(training_history, ax)
plt.show()





print("Testing loss on the validation set.")
regression_model.evaluate(x_validate, y_validate, verbose=2)





y_predict = regression_model.predict(x_validate, verbose=2)





def plot_results(x, y, y_predict, ax):
    ax.scatter(x, y)
    ax.plot(x, y_predict, label="fitted model", color='black')
    ax.set_xlabel('x')
    ax.set_ylabel('y')





fig, ax = plt.subplots()
plot_results(x_validate, y_validate, y_predict, ax)
plt.show()





nn_model = build_nn_model()


training_history = nn_model.fit(
    x, y, 
    batch_size=x.shape[0], 
    verbose=0,
    epochs=2000, 
    validation_data=(x_validate, y_validate)
)


fig, ax = plt.subplots()
plot_loss_history(training_history, ax)
plt.show()





print("Testing loss on the validation set.")
nn_model.evaluate(x_validate, y_validate, verbose=2)





y_predict = nn_model.predict(x_validate, verbose=2)


def plot_results(x, y, y_predict, ax):
    ax.scatter(x, y)
    ax.plot(x, y_predict, label="fitted model", color='black')
    ax.set_xlabel('x')
    ax.set_ylabel('y')


fig, ax = plt.subplots()
plot_results(x_validate, y_validate, y_predict, ax)
plt.show()






